{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captcha.image import ImageCaptcha\n",
    "import cv2\n",
    "import random\n",
    "import string\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras.models import load_model\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(environment, n):\n",
    "    image = ImageCaptcha()\n",
    "    for i in range(n):\n",
    "        rnd = ''.join(random.choice(string.ascii_uppercase) for _ in range(4))\n",
    "        rnd += str(i)\n",
    "        image.write(rnd[:4], environment + '_dataset_full/' + rnd + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset(\"train\", 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset(\"test\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(environment):\n",
    "    filenames = glob.glob(environment + \"_dataset_full/*.png\")\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    x3 = []\n",
    "    x4 = []\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    y3 = []\n",
    "    y4 = []\n",
    "    for img in filenames:\n",
    "        tmp = cv2.imread(img)\n",
    "        # uzeo samo pocetak slike\n",
    "        p1 = tmp[0:60, 0:69]\n",
    "        p2 = tmp[0:60, 20:89]\n",
    "        p3 = tmp[0:60, 40:109]\n",
    "        p4 = tmp[0:60, 60:129]\n",
    "        x1.append(p1)\n",
    "        x2.append(p2)\n",
    "        x3.append(p3)\n",
    "        x4.append(p4)\n",
    "        q1 = ord(img[len(environment)+14])-65\n",
    "        q2 = ord(img[len(environment)+15])-65\n",
    "        q3 = ord(img[len(environment)+16])-65\n",
    "        q4 = ord(img[len(environment)+17])-65\n",
    "        y1.append(q1)\n",
    "        y2.append(q2)\n",
    "        y3.append(q3)\n",
    "        y4.append(q4)\n",
    "    return np.array(x1), np.array(x2), np.array(x3), np.array(x4), np.array(y1), np.array(y2), np.array(y3), np.array(y4), 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x2_train, x3_train, x4_train, y1_train, y2_train, y3_train, y4_train, C = load_dataset(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_test, x2_test, x3_test, x4_test, y1_test, y2_test, y3_test, y4_test, C = load_dataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_data(img_data, threshold):\n",
    "    for i in range(len(img_data)):\n",
    "        for j in range(len(img_data[0])):\n",
    "            for k in range(len(img_data[0][0])):\n",
    "                for l in range(3):\n",
    "                    if img_data[i][j][k][l] > threshold:\n",
    "                        img_data[i][j][k][l] = 0 # black\n",
    "                    else:\n",
    "                        img_data[i][j][k][l] = 255 # max value of channel\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = threshold_data(x1_train, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_train = threshold_data(x2_train, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_train = threshold_data(x3_train, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4_train = threshold_data(x4_train, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_test = threshold_data(x1_test, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_test = threshold_data(x2_test, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_test = threshold_data(x3_test, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4_test = threshold_data(x4_test, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, C):\n",
    "    y_one_hot = np.zeros((y.shape[0], C))\n",
    "    y_one_hot[np.arange(0, y.shape[0]), y] = 1\n",
    "    \n",
    "    return y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = x1_train/255\n",
    "x2_train = x2_train/255\n",
    "x3_train = x3_train/255\n",
    "x4_train = x4_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_test = x1_test/255\n",
    "x2_test = x2_test/255\n",
    "x3_test = x3_test/255\n",
    "x4_test = x4_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = one_hot(y1_train, C)\n",
    "y2_train = one_hot(y2_train, C)\n",
    "y3_train = one_hot(y3_train, C)\n",
    "y4_train = one_hot(y4_train, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_test = one_hot(y1_test, C)\n",
    "y2_test = one_hot(y2_test, C)\n",
    "y3_test = one_hot(y3_test, C)\n",
    "y4_test = one_hot(y4_test, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(image_shape, c):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=image_shape))\n",
    "    model.add(Convolution2D(20, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(40, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(80, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(40, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(c, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, (3, 3), activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(40, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(80, (3, 3), activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(40, (3, 3), activation=\"relu\")`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "model1 = build_model(x1_train[0].shape, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, (3, 3), activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(40, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(80, (3, 3), activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(40, (3, 3), activation=\"relu\")`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model(x2_train[0].shape, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, (3, 3), activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(40, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(80, (3, 3), activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(40, (3, 3), activation=\"relu\")`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "model3 = build_model(x3_train[0].shape, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, (3, 3), activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(40, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(80, (3, 3), activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "D:\\ProgramData\\Anaconda2\\envs\\r-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(40, (3, 3), activation=\"relu\")`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "model4 = build_model(x4_train[0].shape, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss=losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss=losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss=losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5000/5000 [==============================] - 143s 29ms/step - loss: 2.8877 - acc: 0.1530\n",
      "Epoch 2/15\n",
      "5000/5000 [==============================] - 140s 28ms/step - loss: 1.3972 - acc: 0.5552\n",
      "Epoch 3/15\n",
      "5000/5000 [==============================] - 141s 28ms/step - loss: 0.8775 - acc: 0.7198\n",
      "Epoch 4/15\n",
      "5000/5000 [==============================] - 140s 28ms/step - loss: 0.6943 - acc: 0.7878\n",
      "Epoch 5/15\n",
      "5000/5000 [==============================] - 146s 29ms/step - loss: 0.5754 - acc: 0.8250\n",
      "Epoch 6/15\n",
      "5000/5000 [==============================] - 148s 30ms/step - loss: 0.4354 - acc: 0.8648\n",
      "Epoch 7/15\n",
      "5000/5000 [==============================] - 146s 29ms/step - loss: 0.2801 - acc: 0.9136\n",
      "Epoch 8/15\n",
      "5000/5000 [==============================] - 145s 29ms/step - loss: 0.1763 - acc: 0.9442\n",
      "Epoch 9/15\n",
      "5000/5000 [==============================] - 158s 32ms/step - loss: 0.1319 - acc: 0.9574\n",
      "Epoch 10/15\n",
      "5000/5000 [==============================] - 147s 29ms/step - loss: 0.0867 - acc: 0.9772\n",
      "Epoch 11/15\n",
      "5000/5000 [==============================] - 147s 29ms/step - loss: 0.0644 - acc: 0.9780\n",
      "Epoch 12/15\n",
      "5000/5000 [==============================] - 146s 29ms/step - loss: 0.0880 - acc: 0.9774\n",
      "Epoch 13/15\n",
      "5000/5000 [==============================] - 144s 29ms/step - loss: 0.0446 - acc: 0.9870\n",
      "Epoch 14/15\n",
      "5000/5000 [==============================] - 144s 29ms/step - loss: 0.0609 - acc: 0.9820\n",
      "Epoch 15/15\n",
      "5000/5000 [==============================] - 147s 29ms/step - loss: 0.0150 - acc: 0.9958\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(x1_train, y1_train, verbose=1, epochs=15, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5000/5000 [==============================] - 141s 28ms/step - loss: 3.2562 - acc: 0.0418\n",
      "Epoch 2/15\n",
      "5000/5000 [==============================] - 141s 28ms/step - loss: 2.6367 - acc: 0.2084\n",
      "Epoch 3/15\n",
      "5000/5000 [==============================] - 146s 29ms/step - loss: 1.7860 - acc: 0.4354\n",
      "Epoch 4/15\n",
      "5000/5000 [==============================] - 143s 29ms/step - loss: 1.2943 - acc: 0.5812\n",
      "Epoch 5/15\n",
      "5000/5000 [==============================] - 151s 30ms/step - loss: 1.0054 - acc: 0.6842\n",
      "Epoch 6/15\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.8019 - acc: 0.7474\n",
      "Epoch 7/15\n",
      "5000/5000 [==============================] - 152s 30ms/step - loss: 0.6305 - acc: 0.7986\n",
      "Epoch 8/15\n",
      "5000/5000 [==============================] - 152s 30ms/step - loss: 0.4823 - acc: 0.8470\n",
      "Epoch 9/15\n",
      "5000/5000 [==============================] - 151s 30ms/step - loss: 0.3111 - acc: 0.9012\n",
      "Epoch 10/15\n",
      "5000/5000 [==============================] - 150s 30ms/step - loss: 0.2124 - acc: 0.9288\n",
      "Epoch 11/15\n",
      "5000/5000 [==============================] - 151s 30ms/step - loss: 0.1776 - acc: 0.9448\n",
      "Epoch 12/15\n",
      "5000/5000 [==============================] - 151s 30ms/step - loss: 0.1199 - acc: 0.9606\n",
      "Epoch 13/15\n",
      "5000/5000 [==============================] - 151s 30ms/step - loss: 0.1333 - acc: 0.9610\n",
      "Epoch 14/15\n",
      "5000/5000 [==============================] - 151s 30ms/step - loss: 0.1014 - acc: 0.9700\n",
      "Epoch 15/15\n",
      "5000/5000 [==============================] - 150s 30ms/step - loss: 0.0528 - acc: 0.9840\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x2_train, y2_train, verbose=1, epochs=15, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5000/5000 [==============================] - 141s 28ms/step - loss: 3.2584 - acc: 0.0374\n",
      "Epoch 2/15\n",
      "5000/5000 [==============================] - 140s 28ms/step - loss: 2.7653 - acc: 0.1858\n",
      "Epoch 3/15\n",
      "5000/5000 [==============================] - 140s 28ms/step - loss: 1.8685 - acc: 0.4300\n",
      "Epoch 4/15\n",
      "5000/5000 [==============================] - 141s 28ms/step - loss: 1.3752 - acc: 0.5780\n",
      "Epoch 5/15\n",
      "5000/5000 [==============================] - 147s 29ms/step - loss: 1.0807 - acc: 0.6714\n",
      "Epoch 6/15\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.8826 - acc: 0.7286\n",
      "Epoch 7/15\n",
      "5000/5000 [==============================] - 156s 31ms/step - loss: 0.6876 - acc: 0.7828\n",
      "Epoch 8/15\n",
      "5000/5000 [==============================] - 154s 31ms/step - loss: 0.5727 - acc: 0.8212\n",
      "Epoch 9/15\n",
      "5000/5000 [==============================] - 154s 31ms/step - loss: 0.4412 - acc: 0.8600\n",
      "Epoch 10/15\n",
      "5000/5000 [==============================] - 155s 31ms/step - loss: 0.3127 - acc: 0.9062\n",
      "Epoch 11/15\n",
      "5000/5000 [==============================] - 152s 30ms/step - loss: 0.2362 - acc: 0.9240\n",
      "Epoch 12/15\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 0.1641 - acc: 0.9494\n",
      "Epoch 13/15\n",
      "5000/5000 [==============================] - 154s 31ms/step - loss: 0.0602 - acc: 0.9844\n",
      "Epoch 14/15\n",
      "5000/5000 [==============================] - 152s 30ms/step - loss: 0.1169 - acc: 0.9678\n",
      "Epoch 15/15\n",
      "5000/5000 [==============================] - 151s 30ms/step - loss: 0.0618 - acc: 0.9826\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(x3_train, y3_train, verbose=1, epochs=15, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5000/5000 [==============================] - 146s 29ms/step - loss: 3.2590 - acc: 0.0432\n",
      "Epoch 2/15\n",
      "5000/5000 [==============================] - 143s 29ms/step - loss: 3.1305 - acc: 0.0778\n",
      "Epoch 3/15\n",
      "5000/5000 [==============================] - 144s 29ms/step - loss: 2.2824 - acc: 0.3080\n",
      "Epoch 4/15\n",
      "5000/5000 [==============================] - 144s 29ms/step - loss: 1.4354 - acc: 0.5568\n",
      "Epoch 5/15\n",
      "5000/5000 [==============================] - 153s 31ms/step - loss: 1.0200 - acc: 0.6806\n",
      "Epoch 6/15\n",
      "5000/5000 [==============================] - 159s 32ms/step - loss: 0.8196 - acc: 0.7438\n",
      "Epoch 7/15\n",
      "5000/5000 [==============================] - 161s 32ms/step - loss: 0.7195 - acc: 0.7798\n",
      "Epoch 8/15\n",
      "5000/5000 [==============================] - 159s 32ms/step - loss: 0.6907 - acc: 0.7860\n",
      "Epoch 9/15\n",
      "5000/5000 [==============================] - 160s 32ms/step - loss: 0.6334 - acc: 0.8074\n",
      "Epoch 10/15\n",
      "5000/5000 [==============================] - 158s 32ms/step - loss: 0.6129 - acc: 0.8140\n",
      "Epoch 11/15\n",
      "5000/5000 [==============================] - 159s 32ms/step - loss: 0.5780 - acc: 0.8298\n",
      "Epoch 12/15\n",
      "5000/5000 [==============================] - 161s 32ms/step - loss: 0.5432 - acc: 0.8366\n",
      "Epoch 13/15\n",
      "5000/5000 [==============================] - 169s 34ms/step - loss: 0.5431 - acc: 0.8404\n",
      "Epoch 14/15\n",
      "5000/5000 [==============================] - 162s 32ms/step - loss: 0.5558 - acc: 0.8300\n",
      "Epoch 15/15\n",
      "5000/5000 [==============================] - 159s 32ms/step - loss: 0.5382 - acc: 0.8412\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(x4_train, y4_train, verbose=1, epochs=15, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 9s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7870943059921265, 0.775]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 9s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6533738422393798, 0.646]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 9s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.771801127433777, 0.606]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x3_test, y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 9s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0798555126190186, 0.731]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(x4_test, y4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_captcha(text, model1, model2, model3, model4):\n",
    "    if len(text) != 4:\n",
    "        return 'CAPTCHA must have 4 letters'\n",
    "    image = ImageCaptcha()\n",
    "    image.write(text, 'out.png')\n",
    "    y1 = text[0]\n",
    "    y2 = text[1]\n",
    "    y3 = text[2]\n",
    "    y4 = text[3]\n",
    "    tmp = cv2.imread('out.png')\n",
    "    x1 = threshold_data(np.array([tmp[0:60, 0:69]]), 150) / 255\n",
    "    x2 = threshold_data(np.array([tmp[0:60, 20:89]]), 150) / 255\n",
    "    x3 = threshold_data(np.array([tmp[0:60, 40:109]]), 150) / 255\n",
    "    x4 = threshold_data(np.array([tmp[0:60, 60:129]]), 150) / 255\n",
    "    y1_predicted = np.argmax(model1.predict(x1, verbose=1))\n",
    "    y2_predicted = np.argmax(model2.predict(x2, verbose=1))\n",
    "    y3_predicted = np.argmax(model3.predict(x3, verbose=1))\n",
    "    y4_predicted = np.argmax(model4.predict(x4, verbose=1))\n",
    "    print(\"Predicted: \" + chr(y1_predicted+65) + chr(y2_predicted+65) + chr(y3_predicted+65) + chr(y4_predicted+65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('captcha1.h5')\n",
    "model2.save('captcha2.h5')\n",
    "model3.save('captcha3.h5')\n",
    "model4.save('captcha4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predicted: QFEA\n"
     ]
    }
   ],
   "source": [
    "test_captcha('QFEA', model1, model2, model3, model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('captcha1.h5')\n",
    "model2 = load_model('captcha2.h5')\n",
    "model3 = load_model('captcha3.h5')\n",
    "model4 = load_model('captcha4.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
